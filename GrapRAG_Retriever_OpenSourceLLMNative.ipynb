{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the the graph in Neo4J\n",
    "MATCH (n)\n",
    "OPTIONAL MATCH (n)-[r]-(m)\n",
    "RETURN n, r, m\n",
    "\n",
    "# Delete the the graph in Neo4J\n",
    "MATCH (n)\n",
    "DETACH DELETE n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HzNIxRCZmW7W"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-community langchain-ollama  langchain-experimental neo4j wikipedia tiktoken yfiles_jupyter_graphs python-dotenv json-repair langchain-openai langchain_core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/env_graphrag_test1/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from neo4j import GraphDatabase\n",
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_ollama import OllamaEmbeddings,ChatOllama\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import Tuple, List, Optional\n",
    "from yfiles_jupyter_graphs import GraphWidget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YiKFX23n4tl3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/40/gnhyngsx3gnc1bc9rjrsgm380000gn/T/ipykernel_3340/3887310121.py:10: LangChainDeprecationWarning: The class `Neo4jGraph` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :class:`~langchain-neo4j` and import as `from :class:`~langchain_neo4j import Neo4jGraph``.\n",
      "  graph = Neo4jGraph()\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set them in the OS environment\n",
    "os.environ[\"NEO4J_URI\"] = os.getenv(\"NEO4J_URI\")\n",
    "os.environ[\"NEO4J_USERNAME\"] = os.getenv(\"NEO4J_USERNAME\")\n",
    "os.environ[\"NEO4J_PASSWORD\"] = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "#Instantiate the Graph DB\n",
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IMh_IpRb78rs"
   },
   "outputs": [],
   "source": [
    "# It initialise a language model.\n",
    "\n",
    "# It gets the entities from the user's question\n",
    "model_entity=\"qwen2:7b\" \n",
    "\n",
    "# It translates the cypher langaue into human language\n",
    "model_translator=\"qwen2:7b\" \n",
    "\n",
    "# It generates the responses based on the given context\n",
    "model_generator=\"deepseek-r1:14b\" \n",
    "#model_generator=\"mistral-small:latest\"\n",
    "#model_generator=\"tulu3:8b\"\n",
    "#model_generator=\"qwen2.5:32b\"\n",
    "\n",
    "\n",
    "llm_entity = ChatOllama(model=model_entity, temperature=0, format=\"json\")\n",
    "llm_translator = ChatOllama(model=model_translator, temperature=0, format=\"json\")\n",
    "llm_generator = ChatOllama(model=model_generator, temperature=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rC-4O5FQ99yH"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b90863d552b4beebb0ebe9d02f14ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='800px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b90863d552b4beebb0ebe9d02f14ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='800px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Ploting the Graph ###\n",
    "\n",
    "# It finds relationships between nodes where the relationship type is NOT \"MENTIONS\".\n",
    "#default_cypher = \"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t LIMIT 50\"\n",
    "default_cypher = \"MATCH (n) OPTIONAL MATCH (n)-[r]-(m) RETURN n, r, m\"\n",
    "\n",
    "#default_cypher = \"MATCH (s)-[r]->(t) WHERE NOT type(r) = 'MENTIONS' RETURN s,r,t LIMIT 50\"\n",
    "\n",
    "# GraphWidget: A visualisation tool for rendering and exploring graphs in Jupyter Notebooks.\n",
    "# GraphDatabase: The official Neo4j driver for querying and updating graph data in a Neo4j database.\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "\n",
    "# It checks if the script is running in Google Colab and, if so, enable support for custom widgets.\n",
    "try:\n",
    "  import google.colab\n",
    "  from google.colab import output\n",
    "  output.enable_custom_widget_manager()\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# It runs a Cypher query on a Neo4j graph database to retrieve data (nodes and relationships).\n",
    "# It visualises the graph data interactively using GraphWidget from the yfiles_jupyter_graphs library.\n",
    "def showGraph(cypher: str = default_cypher):\n",
    "    # create a neo4j session to run queries\n",
    "    driver = GraphDatabase.driver(\n",
    "        uri = os.environ[\"NEO4J_URI\"],\n",
    "        auth = (os.environ[\"NEO4J_USERNAME\"],\n",
    "                os.environ[\"NEO4J_PASSWORD\"]))\n",
    "    session = driver.session()\n",
    "    widget = GraphWidget(graph = session.run(cypher).graph())\n",
    "    widget.node_label_mapping = 'id'\n",
    "    display(widget)\n",
    "    return widget\n",
    "\n",
    "\n",
    "showGraph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M_JloAimBlcK"
   },
   "outputs": [],
   "source": [
    "                                            ### Database Settings ###\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = OllamaEmbeddings(\n",
    "#model=\"mxbai-embed-large\",\n",
    "model=\"rjmalagon/gte-qwen2-1.5b-instruct-embed-f16:latest\",\n",
    ")\n",
    "\n",
    "# Create a vector index from the existing graph\n",
    "vector_index =Neo4jVector.from_existing_graph(\n",
    "embeddings,\n",
    "search_type=\"hybrid\",\n",
    "node_label=\"Document\",\n",
    "text_node_properties=[\"text\"],\n",
    "embedding_node_property=\"embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0EXdSStG-Oe",
    "outputId": "443d0af8-1043-4dec-f842-2e9959109941"
   },
   "outputs": [],
   "source": [
    "                                            ### Structured Data Retriever: Graph ###\n",
    "\n",
    "\n",
    "### 1. Entity Extraction\n",
    "\n",
    "# It creates a full-text search index in a Neo4j graph database for nodes with the label Entity.\n",
    "# Full-text indexes are used to efficiently search text fields, especially when searching for words, phrases, or patterns in text properties.\n",
    "graph.query(\"CREATE FULLTEXT INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\")\n",
    "\n",
    "\n",
    "# It defines a Pydantic model using BaseModel from the langchain_core.pydantic_v1 module. The model, named Entities, is used to structure and validate data related to entities extracted from text.\n",
    "# Extract entities from text\n",
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "\n",
    "    names: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"All the person, organization, or business entities that \"\n",
    "        \"appear in the text\",\n",
    "    )\n",
    "\n",
    "# This template is designed for extracting named entities (organisations and persons) from text.\n",
    "# It defines a structured conversation designed for an AI model to perform entity extraction (specifically for organisations and persons) from a given text input.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are extracting organization and person entities from the text.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following \"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# It creates a \"chain\" or pipeline where:\n",
    "# A prompt (from ChatPromptTemplate) defines the structure of the input or task.\n",
    "# The LLM processes the prompt to generate an output.\n",
    "# The output is returned in a structured format, defined by a class or schema (here, Entities).\n",
    "dict_schema = convert_to_openai_function(Entities)\n",
    "entity_chain = prompt | llm_entity.with_structured_output(dict_schema)\n",
    "\n",
    "\n",
    "### 2. Entity Extraction\n",
    "\n",
    "# 2.1 It generates a full-text search query for a given input string\n",
    "def generate_full_text_query(input: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a full-text search query for a given input string.\n",
    "\n",
    "    This function constructs a query string suitable for a full-text search.\n",
    "    It processes the input string by splitting it into words and appending a\n",
    "    similarity threshold (~2 changed characters) to each word, then combines\n",
    "    them using the AND operator. Useful for mapping entities from user questions\n",
    "    to database values, and allows for some misspelings.\n",
    "    \"\"\"\n",
    "\n",
    "    full_text_query = \"\"\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    for word in words[:-1]:\n",
    "        full_text_query += f\" {word}~2 AND\"\n",
    "    full_text_query += f\" {words[-1]}~2\"\n",
    "    return full_text_query.strip()\n",
    "\n",
    "# 2.2 It converts entiy relationship language into human language. Example: Deepseek - PART_OF -> Ai Space Race = Deepseek is part of Ai Space Race    \n",
    "def convert_cypher_to_text(context: str) -> str:\n",
    "\n",
    "    # Define the prompt template\n",
    "    template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert in converting cypher language statements into natural language sentences based on the given context.\"),\n",
    "        (\"human\", \"{user_input}\")\n",
    "    ])\n",
    "    \n",
    "    # Format the user question for translation\n",
    "    user_input = f\"\"\" Convert the given cypher language statements into human-readable language.\n",
    "    Each statement follows the pattern:  \"Entity - RELATIONSHIP -> Target\"\n",
    "    \n",
    "    Follow these guidelines:\n",
    "    \n",
    "    1. Convert the entity and target into readable names without modification.\n",
    "    2. Convert the relationship into a natural language phrase based on common meanings.\n",
    "    3. Ensure the sentence is grammatically correct and clear.\n",
    "    \n",
    "    Example Input:\n",
    "    Deepseek - PART_OF -> Ai Space Race\n",
    "    Deepseek - HAS_NAME -> Shendu Qiusuo\n",
    "    Deepseek - DEVELOPS -> Artificial Intelligence\n",
    "    \n",
    "    Example Output:\n",
    "    Deepseek is part of Ai Space Race\n",
    "    Deepseek is named Shendu Qiusuo\n",
    "    Deepseek develops Artificial Intelligence.\n",
    "\n",
    "    \n",
    "    Now, translate the following cypher languange statements into human-readable language based on the following context:\n",
    "    \n",
    "    {context}\n",
    "    \n",
    "    Ouput:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate messages and invoke the LLM response\n",
    "    messages = template.format_messages(user_input=user_input)\n",
    "    response = llm_translator.invoke(messages)\n",
    "    #print(response.content)\n",
    "    return response\n",
    "\n",
    "# 2.3 It extracts and returns all sentences after the ':' character\n",
    "def extract_converted_cypher(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts and returns all sentences after the ':' character,\n",
    "    ensuring each sentence ends with a period, separated by a line break.\n",
    "    \"\"\"\n",
    "    sentences = re.findall(r':\\s*\"(.*?)\"', text)\n",
    "    sentences = [s if s.endswith('.') else s + '.' for s in sentences]\n",
    "    return \"\\n\".join(sentences)\n",
    "\n",
    "\n",
    "# 2.4 It performs structured retrieval of information from a Neo4j graph database based on an input question. It combines entity extraction, full-text search, and graph traversal to return relationships involving extracted entities.\n",
    "def structured_retriever(question: str) -> str:\n",
    "    result = \"\"\n",
    "    entities = entity_chain.invoke({\"question\": question})\n",
    "    entity_names =entities['names']\n",
    "    \n",
    "    for entity in entity_names:\n",
    "        response = graph.query(\n",
    "            \"\"\"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\n",
    "            YIELD node,score\n",
    "            CALL {\n",
    "              WITH node\n",
    "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
    "              UNION ALL\n",
    "              WITH node\n",
    "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n",
    "            }\n",
    "            RETURN output LIMIT 100\n",
    "            \"\"\",\n",
    "            {\"query\": generate_full_text_query(entity)},\n",
    "        )\n",
    "        #result += \"\\n\".join([el['output'] for el in response])\n",
    "        for el in response:\n",
    "          #print(\"ddd:\",el['output'])  # Print each output separately\n",
    "          result += el['output'] + \"\\n\"  # Append to result if needed\n",
    "        partial_result= convert_cypher_to_text(result)\n",
    "        final_result=extract_converted_cypher(partial_result.content)\n",
    "    return final_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                        ### Unstructured Data Retriever: Chunks-based ###\n",
    "\n",
    "# It gets the top 15 similar chunks based on the users input\n",
    "def unstructured_retriever(question: str) -> str:\n",
    "    result= [el.page_content for el in vector_index.similarity_search(question, k = 15)]\n",
    "\n",
    "    return result   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The DeepSeek-R1 model', \"OpenAI's GPT-4\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Testing the Entity extraction\n",
    "entities=entity_chain.invoke({\"question\": \"The DeepSeek-R1 model provides responses comparable to other contemporary large language models, such as OpenAI's GPT-4o and o1.\"})\n",
    "entity_names =entities['names']\n",
    "entity_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/40/gnhyngsx3gnc1bc9rjrsgm380000gn/T/ipykernel_3340/1353653323.py:61: LangChainDeprecationWarning: The function `remove_lucene_chars` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the function exists in the :meth:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :meth:`~langchain-neo4j` and import as `from :meth:`~langchain_neo4j.vectorstores.neo4j_vector import remove_lucene_chars``.\n",
      "  words = [el for el in remove_lucene_chars(input).split() if el]\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 100\\n            \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 100\\n            \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documenting includes What Works.\n",
      "Documenting includes What Doesn’t Work.\n",
      "Deepseek-R1 affects the Internet.\n",
      "Deepseek-R1 impacts the Stock Market.\n",
      "Deepseek-R1 performed as well or better than O1.\n",
      "Deepseek-R1 is accompanied by a Tech Report.\n",
      "Deepseek-R1 leaves an open question about Data Collection.\n",
      "Deepseek-R1 leaves an open question about Model Training.\n",
      "Deepseek-R1 contributes to Open-R1.\n",
      "Deepseek-R1 is built on the foundation of Deepseek-V3.\n",
      "Deepseek-R1 benefits the Community.\n",
      "Deepseek-R1-Zero uses Group Relative Policy Optimization.\n",
      "Deepseek-R1-Zero skips Supervised Fine-Tuning.\n",
      "Deepseek-R1-Zero relies on Reinforcement Learning.\n",
      "Reproduction of Open-R1 leads to Deepseek-R1.\n",
      "The reconstruction of the Open-R1 Project results in Deepseek-R1.\n",
      "Deepseek introduces Deepseek-R1.\n",
      "The Reasoning Dataset originates from Deepseek-R1.\n",
      "Deepseek releases Deepseek-R1.\n",
      "Model weights are open for Deepseek-R1.\n",
      "Datasets are not open for Deepseek-R1.\n",
      "The code is not open for Deepseek-R1.\n",
      "Deepseek introduces Deepseek-R1-Zero.\n"
     ]
    }
   ],
   "source": [
    "### Testing the structured retriever\n",
    "print(structured_retriever(\"What is DeepSeek-R1?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGR6ocjkA0I_",
    "outputId": "765c055a-4638-413c-f450-b011bb549588"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ntext: However, the DeepSeek-R1 release leaves open several questions about:\\n•\\tData collection: How were the reasoning-specific datasets curated?\\n•\\tModel training: No training code was released by DeepSeek, so it is unknown which hyperparameters work best and how they differ across different model families and scales.', '\\ntext: Open-R1: a fully open reproduction of DeepSeek-R1\\nWhat is DeepSeek-R1?\\nIf you’ve ever struggled with a tough math problem, you know how useful it is to think a little longer and work through it carefully.', '\\ntext: Besides performing as well or better than o1, the DeepSeek-R1 release was accompanied by a detailed tech report that outlined the key steps of their training recipe.', '\\ntext: That’s where DeepSeek-R1 comes in.', '\\ntext: In this blog post we take a look at key ingredients behind DeepSeek-R1, which parts we plan to replicate, and how to contribute to the Open-R1 project.', '\\ntext: •\\tScaling laws: What are the compute and data trade-offs in training reasoning models?\\n\\nThese questions prompted us to launch the Open-R1 project, an initiative to systematically reconstruct DeepSeek-R1’s data and training pipeline, validate its claims, and push the boundaries of open reasoning models.', '\\ntext: How did they do it?\\nDeepSeek-R1 is a reasoning model built on the foundation of DeepSeek-V3.', '\\ntext: The goal of Open-R1 is to build these last missing pieces so that the whole research and industry community can build similar or better models using these recipes and datasets.', '\\ntext: •\\tStep 2: Replicate the pure RL pipeline that DeepSeek used to create R1-Zero.', '\\ntext: 5M—thanks to architectural changes like Multi Token Prediction (MTP), Multi-Head Latent Attention (MLA) and a LOT (seriously, a lot) of hardware optimization.', '\\ntext: And by doing this in the open, everybody in the community can contribute!\\nAs shown in the figure below, here’s our plan of attack\\n•\\tStep 1: Replicate the R1-Distill models by distilling a high-quality reasoning dataset from DeepSeek-R1.', '\\ntext: DeepSeek also introduced two models: DeepSeek-R1-Zero and DeepSeek-R1, each with a distinct training approach.', '\\ntext: That is, until last week, when DeepSeek released their DeepSeek-R1 model and promptly broke the internet (and the stock market!).', '\\ntext: DeepSeek-R1-Zero skipped supervised fine-tuning altogether and relied entirely on reinforcement learning (RL), using Group Relative Policy Optimization (GRPO) to make the process more efficient.', '\\ntext: Open-R1: the missing pieces\\nThe release of DeepSeek-R1 is an amazing boon for the community, but they didn’t release everything—although the model weights are open, the datasets and code used to train the model are not.']\n"
     ]
    }
   ],
   "source": [
    "### Testing the unstructured retriever\n",
    "print(unstructured_retriever(\"What is DeepSeek-R1?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                ### Final Retriever ###\n",
    "\n",
    "# It combines structured data retrieval (from a graph database) with unstructured data retrieval (from a vector-based search index).\n",
    "# It creates a unified result containing both types of data for a given question.\n",
    "def retriever(question: str, query_type:str):\n",
    "    print(f\"Search query: {question}\")\n",
    "    if query_type==\"graph\":\n",
    "        structured_data = structured_retriever(question)\n",
    "        final_data = f\"\"\"Structured data:\n",
    "                    {structured_data}\n",
    "                   \"\"\"\n",
    "\n",
    "    if query_type==\"similarity\":\n",
    "        unstructured_data = unstructured_retriever(question)\n",
    "\n",
    "        final_data = f\"\"\"Unstructured data:\n",
    "                        {\"#Document \". join(unstructured_data)}\n",
    "                    \"\"\"\n",
    "        \n",
    "    if query_type==\"hybrid\":\n",
    "        structured_data = structured_retriever(question)\n",
    "        unstructured_data = unstructured_retriever(question)\n",
    "        \n",
    "        final_data = f\"\"\"Structured data:\n",
    "                    {structured_data}\n",
    "                    Unstructured data:\n",
    "                        {\"#Document \". join(unstructured_data)}\n",
    "                    \"\"\"\n",
    "    print(\"RETRIEVER-OUTPUT:\\n\",final_data)\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query: What is DeepSeek?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 100\\n            \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RETRIEVER-OUTPUT:\n",
      " Structured data:\n",
      "                    Deepseek was introduced as Deepseek-R1.\n",
      "Deepseek was introduced with the version Deepseek-R1-Zero.\n",
      "Deepseek-R1 was released by Deepseek.\n",
      "Deepseek-R1 impacted the Internet.\n",
      "Deepseek-R1 influenced the stock market.\n",
      "Deepseek-R1 outperformed or matched O1 in performance.\n",
      "Deepseek-R1 was accompanied by a tech report.\n",
      "Deepseek-R1 raises an open question regarding data collection.\n",
      "Deepseek-R1 poses an open question about model training.\n",
      "Deepseek-R1 contributes to the development of Open-R1.\n",
      "Deepseek-R1 was developed based on the foundation of Deepseek-V3.\n",
      "Deepseek-R1 benefits the community.\n",
      "The Pure Rl Pipeline is utilized by Deepseek.\n",
      "Reproduction of Open-R1 led to the creation of Deepseek-R1.\n",
      "Deepseek-R1 was reconstructed based on the Open-R1 Project.\n",
      "Deepseek introduced Deepseek-R1.\n",
      "Deepseek-R1 was officially released by Deepseek.\n",
      "The model weights for Deepseek-R1 are accessible or open.\n",
      "The datasets related to Deepseek-R1 are not publicly available or closed.\n",
      "The code associated with Deepseek-R1 is not publicly accessible or closed.\n",
      "                    Unstructured data:\n",
      "                        \n",
      "text: However, the DeepSeek-R1 release leaves open several questions about:\n",
      "•\tData collection: How were the reasoning-specific datasets curated?\n",
      "•\tModel training: No training code was released by DeepSeek, so it is unknown which hyperparameters work best and how they differ across different model families and scales.#Document \n",
      "text: Open-R1: a fully open reproduction of DeepSeek-R1\n",
      "What is DeepSeek-R1?\n",
      "If you’ve ever struggled with a tough math problem, you know how useful it is to think a little longer and work through it carefully.#Document \n",
      "text: That’s where DeepSeek-R1 comes in.#Document \n",
      "text: Besides performing as well or better than o1, the DeepSeek-R1 release was accompanied by a detailed tech report that outlined the key steps of their training recipe.#Document \n",
      "text: In this blog post we take a look at key ingredients behind DeepSeek-R1, which parts we plan to replicate, and how to contribute to the Open-R1 project.#Document \n",
      "text: How did they do it?\n",
      "DeepSeek-R1 is a reasoning model built on the foundation of DeepSeek-V3.#Document \n",
      "text: •\tScaling laws: What are the compute and data trade-offs in training reasoning models?\n",
      "\n",
      "These questions prompted us to launch the Open-R1 project, an initiative to systematically reconstruct DeepSeek-R1’s data and training pipeline, validate its claims, and push the boundaries of open reasoning models.#Document \n",
      "text: 5M—thanks to architectural changes like Multi Token Prediction (MTP), Multi-Head Latent Attention (MLA) and a LOT (seriously, a lot) of hardware optimization.#Document \n",
      "text: DeepSeek also introduced two models: DeepSeek-R1-Zero and DeepSeek-R1, each with a distinct training approach.#Document \n",
      "text: •\tStep 2: Replicate the pure RL pipeline that DeepSeek used to create R1-Zero.#Document \n",
      "text: And by doing this in the open, everybody in the community can contribute!\n",
      "As shown in the figure below, here’s our plan of attack\n",
      "•\tStep 1: Replicate the R1-Distill models by distilling a high-quality reasoning dataset from DeepSeek-R1.#Document \n",
      "text: The goal of Open-R1 is to build these last missing pieces so that the whole research and industry community can build similar or better models using these recipes and datasets.#Document \n",
      "text: Open-R1: the missing pieces\n",
      "The release of DeepSeek-R1 is an amazing boon for the community, but they didn’t release everything—although the model weights are open, the datasets and code used to train the model are not.#Document \n",
      "text: That is, until last week, when DeepSeek released their DeepSeek-R1 model and promptly broke the internet (and the stock market!).#Document \n",
      "text: DeepSeek-R1-Zero skipped supervised fine-tuning altogether and relied entirely on reinforcement learning (RL), using Group Relative Policy Optimization (GRPO) to make the process more efficient.\n",
      "                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Structured data:\\n                    Deepseek was introduced as Deepseek-R1.\\nDeepseek was introduced with the version Deepseek-R1-Zero.\\nDeepseek-R1 was released by Deepseek.\\nDeepseek-R1 impacted the Internet.\\nDeepseek-R1 influenced the stock market.\\nDeepseek-R1 outperformed or matched O1 in performance.\\nDeepseek-R1 was accompanied by a tech report.\\nDeepseek-R1 raises an open question regarding data collection.\\nDeepseek-R1 poses an open question about model training.\\nDeepseek-R1 contributes to the development of Open-R1.\\nDeepseek-R1 was developed based on the foundation of Deepseek-V3.\\nDeepseek-R1 benefits the community.\\nThe Pure Rl Pipeline is utilized by Deepseek.\\nReproduction of Open-R1 led to the creation of Deepseek-R1.\\nDeepseek-R1 was reconstructed based on the Open-R1 Project.\\nDeepseek introduced Deepseek-R1.\\nDeepseek-R1 was officially released by Deepseek.\\nThe model weights for Deepseek-R1 are accessible or open.\\nThe datasets related to Deepseek-R1 are not publicly available or closed.\\nThe code associated with Deepseek-R1 is not publicly accessible or closed.\\n                    Unstructured data:\\n                        \\ntext: However, the DeepSeek-R1 release leaves open several questions about:\\n•\\tData collection: How were the reasoning-specific datasets curated?\\n•\\tModel training: No training code was released by DeepSeek, so it is unknown which hyperparameters work best and how they differ across different model families and scales.#Document \\ntext: Open-R1: a fully open reproduction of DeepSeek-R1\\nWhat is DeepSeek-R1?\\nIf you’ve ever struggled with a tough math problem, you know how useful it is to think a little longer and work through it carefully.#Document \\ntext: That’s where DeepSeek-R1 comes in.#Document \\ntext: Besides performing as well or better than o1, the DeepSeek-R1 release was accompanied by a detailed tech report that outlined the key steps of their training recipe.#Document \\ntext: In this blog post we take a look at key ingredients behind DeepSeek-R1, which parts we plan to replicate, and how to contribute to the Open-R1 project.#Document \\ntext: How did they do it?\\nDeepSeek-R1 is a reasoning model built on the foundation of DeepSeek-V3.#Document \\ntext: •\\tScaling laws: What are the compute and data trade-offs in training reasoning models?\\n\\nThese questions prompted us to launch the Open-R1 project, an initiative to systematically reconstruct DeepSeek-R1’s data and training pipeline, validate its claims, and push the boundaries of open reasoning models.#Document \\ntext: 5M—thanks to architectural changes like Multi Token Prediction (MTP), Multi-Head Latent Attention (MLA) and a LOT (seriously, a lot) of hardware optimization.#Document \\ntext: DeepSeek also introduced two models: DeepSeek-R1-Zero and DeepSeek-R1, each with a distinct training approach.#Document \\ntext: •\\tStep 2: Replicate the pure RL pipeline that DeepSeek used to create R1-Zero.#Document \\ntext: And by doing this in the open, everybody in the community can contribute!\\nAs shown in the figure below, here’s our plan of attack\\n•\\tStep 1: Replicate the R1-Distill models by distilling a high-quality reasoning dataset from DeepSeek-R1.#Document \\ntext: The goal of Open-R1 is to build these last missing pieces so that the whole research and industry community can build similar or better models using these recipes and datasets.#Document \\ntext: Open-R1: the missing pieces\\nThe release of DeepSeek-R1 is an amazing boon for the community, but they didn’t release everything—although the model weights are open, the datasets and code used to train the model are not.#Document \\ntext: That is, until last week, when DeepSeek released their DeepSeek-R1 model and promptly broke the internet (and the stock market!).#Document \\ntext: DeepSeek-R1-Zero skipped supervised fine-tuning altogether and relied entirely on reinforcement learning (RL), using Group Relative Policy Optimization (GRPO) to make the process more efficient.\\n                    '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Testing the final retriever\n",
    "retriever(\"What is DeepSeek?\",\"hybrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                    ### Generator ###\n",
    "# It includes the context(retrieval output) into the LLM based on the query type and response the user's question. \n",
    "def get_response(question: str, query_type:str):\n",
    "\n",
    "    template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an AI assistant using a Retrieval-Augmented Generation (RAG) system to provide accurate answers based on the given context.\"),\n",
    "        (\"human\", \"{user_input}\")\n",
    "    ])\n",
    "    \n",
    "    context = retriever(question,query_type) # The options are: graph, similarity, hybrid.\n",
    "    \n",
    "    user_question = f\"\"\"Answer the question following these guidelines:\n",
    "    \n",
    "    - Answer the question based *only* on the provided context.\n",
    "    - Make inference based on the provided context noy based on your knowlege.\n",
    "    - If the context does not contain enough information, state: \"I do not have enough information to answer your question.\"\n",
    "    - If you dont know the answer, state: \"I do not know the answer to your question.\"\n",
    "    - Use clear, natural, and professional language in your response.\n",
    "    - Avoid making up information or speculating beyond the provided context.\n",
    "    - If applicable, provide citations or references to the retrieved context.\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    messages = template.format_messages(user_input=user_question)\n",
    "    response = llm_generator.invoke(messages)\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query: What is DeepSeek-R1?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 100\\n            \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 100\\n            \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RETRIEVER-OUTPUT:\n",
      " Structured data:\n",
      "                    Documenting includes What Works.\n",
      "Documenting includes What Doesn’t Work.\n",
      "Deepseek-R1 affects the Internet.\n",
      "Deepseek-R1 impacts the Stock Market.\n",
      "Deepseek-R1 performed as well or better than O1.\n",
      "Deepseek-R1 is accompanied by a Tech Report.\n",
      "Deepseek-R1 leaves an open question about Data Collection.\n",
      "Deepseek-R1 leaves an open question about Model Training.\n",
      "Deepseek-R1 contributes to Open-R1.\n",
      "Deepseek-R1 is built on the foundation of Deepseek-V3.\n",
      "Deepseek-R1 benefits the Community.\n",
      "Deepseek-R1-Zero uses Group Relative Policy Optimization.\n",
      "Deepseek-R1-Zero skips Supervised Fine-Tuning.\n",
      "Deepseek-R1-Zero relies on Reinforcement Learning.\n",
      "Reproduction of Open-R1 leads to Deepseek-R1.\n",
      "The reconstruction of the Open-R1 Project results in Deepseek-R1.\n",
      "Deepseek introduces Deepseek-R1.\n",
      "The Reasoning Dataset originates from Deepseek-R1.\n",
      "Deepseek releases Deepseek-R1.\n",
      "Model weights are open for Deepseek-R1.\n",
      "Datasets are not open for Deepseek-R1.\n",
      "The code is not open for Deepseek-R1.\n",
      "Deepseek introduces Deepseek-R1-Zero.\n",
      "                   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, so I need to figure out what DeepSeek-R1 is based on the provided context. Let me go through each point one by one.\\n\\nFirst, it says that Deepseek-R1 affects the Internet and impacts the Stock Market. That suggests it's some kind of tool or system used in financial contexts, maybe for trading or analysis.\\n\\nNext, it performed as well or better than O1. I'm not sure what O1 refers to, but it seems like a competitor or another version. So Deepseek-R1 is at least as good if not better than this other thing.\\n\\nDeepseek-R1 comes with a Tech Report, which probably means there's documentation or technical details available about it. That makes sense for something that's being released formally.\\n\\nIt leaves open questions about Data Collection and Model Training. This implies that while the system has been developed, there are still areas where improvements can be made in how data is gathered and models are trained.\\n\\nDeepseek-R1 contributes to Open-R1. I'm not sure what Open-R1 is exactly, but maybe it's a project or initiative that Deepseek-R1 supports or enhances.\\n\\nIt's built on the foundation of Deepseek-V3. So this is an evolution from a previous version, V3, which probably had some established features and capabilities.\\n\\nDeepseek-R1 benefits the Community, so it's likely open-source or has some community-driven aspects, allowing others to contribute or use it for their purposes.\\n\\nLooking at the Zero variant, Deepseek-R1-Zero uses Group Relative Policy Optimization. That sounds like a specific technique in machine learning, possibly related to reinforcement learning since another point mentions that R1-Zero relies on Reinforcement Learning and skips Supervised Fine-Tuning.\\n\\nReproduction of Open-R1 leads to Deepseek-R1, which might mean that by replicating or building upon Open-R1's work, they developed their own version, Deepseek-R1. Similarly, reconstructing the Open-R1 Project results in Deepseek-R1, reinforcing that idea.\\n\\nDeepseek introduces both Deepseek-R1 and its Zero variant, so they are the creators of these systems.\\n\\nThe Reasoning Dataset originates from Deepseek-R1, indicating that it's used to create or test datasets related to reasoning tasks. However, while model weights are open for Deepseek-R1, the datasets themselves aren't, which might limit some aspects of community contribution or third-party use.\\n\\nThe code isn't open for Deepseek-R1 either, so access is limited in that regard. But they do introduce Deepseek-R1-Zero, which I assume has different characteristics, possibly being more accessible or optimized differently.\\n\\nPutting this all together, Deepseek-R1 seems to be a system developed by Deepseek, likely related to financial applications given its impact on the stock market and internet. It's built upon an earlier version (V3) and has a Zero variant that uses reinforcement learning without supervised fine-tuning. The system contributes to Open-R1 and includes a tech report but doesn't open up all aspects like datasets or code, except for model weights.\\n\\nI should make sure I'm not adding any information beyond what's provided. For example, I don't know the exact purpose of Open-R1, so I shouldn't speculate on that. Also, while it's clear that R1-Zero uses reinforcement learning, I shouldn't assume anything about its performance or specific applications unless stated.\\n\\nSo in the answer, I'll list these points clearly, making sure to reference each aspect from the context without adding any external knowledge.\\n</think>\\n\\nDeepSeek-R1 is a system developed by Deepseek, primarily impacting financial contexts such as stock market analysis. It demonstrates comparable or superior performance to O1, another system, and includes a Tech Report for documentation. While contributing to Open-R1, an initiative it supports, Deepseek-R1 raises considerations regarding data collection and model training methodologies.\\n\\nThe system is built on the foundation of Deepseek-V3 and offers two variants: the main version and Deepseek-R1-Zero. The Zero variant employs Group Relative Policy Optimization and reinforcement learning, avoiding supervised fine-tuning. Although model weights are accessible, datasets and code for Deepseek-R1 remain closed-source, potentially limiting community contributions beyond model usage.\\n\\nIn summary, DeepSeek-R1 is a financial tool developed by Deepseek, leveraging advanced machine learning techniques, with its Zero variant optimized for reinforcement learning without traditional fine-tuning methods.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the Generator\n",
    "get_response(\"What is DeepSeek-R1?\",\"graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "c99b857b2235458fbe236ac4a199e8e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": "800px",
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "f73b90bfb4594fcabb8d52bf07fb08b3": {
     "model_module": "yfiles-jupyter-graphs",
     "model_module_version": "^1.10.1",
     "model_name": "GraphModel",
     "state": {
      "_context_pane_mapping": [
       {
        "id": "Neighborhood",
        "title": "Neighborhood"
       },
       {
        "id": "Data",
        "title": "Data"
       },
       {
        "id": "Search",
        "title": "Search"
       },
       {
        "id": "About",
        "title": "About"
       }
      ],
      "_data_importer": "neo4j",
      "_directed": true,
      "_dom_classes": [],
      "_edges": [
       {
        "color": "#CDDC39",
        "directed": true,
        "end": 8,
        "id": 1152925902653358000,
        "label": "RESEARCH",
        "properties": {
         "label": "RESEARCH"
        },
        "start": 4,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9E9E9E",
        "directed": true,
        "end": 6,
        "id": 1152939096792891400,
        "label": "PROFESSOR",
        "properties": {
         "label": "PROFESSOR"
        },
        "start": 4,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9C27B0",
        "directed": true,
        "end": 7,
        "id": 1152951191420797000,
        "label": "AWARDED",
        "properties": {
         "label": "AWARDED"
        },
        "start": 4,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#2196F3",
        "directed": true,
        "end": 12,
        "id": 1152952290932424700,
        "label": "AWARDED_IN",
        "properties": {
         "label": "AWARDED_IN"
        },
        "start": 4,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#2196F3",
        "directed": true,
        "end": 13,
        "id": 1155204090746110000,
        "label": "AWARDED_IN",
        "properties": {
         "label": "AWARDED_IN"
        },
        "start": 4,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9C27B0",
        "directed": true,
        "end": 7,
        "id": 1152951191420797000,
        "label": "AWARDED",
        "properties": {
         "label": "AWARDED"
        },
        "start": 5,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#4CAF50",
        "directed": true,
        "end": 1,
        "id": 1155206289769365500,
        "label": "QUEEN_OF",
        "properties": {
         "label": "QUEEN_OF"
        },
        "start": 9,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#4CAF50",
        "directed": true,
        "end": 15,
        "id": 1152954489955680300,
        "label": "QUEEN_OF",
        "properties": {
         "label": "QUEEN_OF"
        },
        "start": 9,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#F44336",
        "directed": true,
        "end": 14,
        "id": 1152955589467308000,
        "label": "MEMBER_OF",
        "properties": {
         "label": "MEMBER_OF"
        },
        "start": 9,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#607D8B",
        "directed": true,
        "end": 10,
        "id": 1152956688978935800,
        "label": "CHILD_OF",
        "properties": {
         "label": "CHILD_OF"
        },
        "start": 9,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#607D8B",
        "directed": true,
        "end": 11,
        "id": 1155208488792621000,
        "label": "CHILD_OF",
        "properties": {
         "label": "CHILD_OF"
        },
        "start": 9,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 16,
        "id": 1152959987513819100,
        "label": "SIBLING_OF",
        "properties": {
         "label": "SIBLING_OF"
        },
        "start": 9,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 18,
        "id": 1155211787327504400,
        "label": "SIBLING_OF",
        "properties": {
         "label": "SIBLING_OF"
        },
        "start": 9,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#CDDC39",
        "directed": true,
        "end": 19,
        "id": 1152963286048702500,
        "label": "ADVISED_BY",
        "properties": {
         "label": "ADVISED_BY"
        },
        "start": 9,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9E9E9E",
        "directed": true,
        "end": 21,
        "id": 1152965485071958000,
        "label": "SUPREME_GOVERNOR_OF",
        "properties": {
         "label": "SUPREME_GOVERNOR_OF"
        },
        "start": 9,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9C27B0",
        "directed": true,
        "end": 22,
        "id": 1152966584583585800,
        "label": "SUCCEEDED_BY",
        "properties": {
         "label": "SUCCEEDED_BY"
        },
        "start": 9,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#2196F3",
        "directed": true,
        "end": 24,
        "id": 1152967684095213600,
        "label": "PROTECTED_BY",
        "properties": {
         "label": "PROTECTED_BY"
        },
        "start": 9,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#4CAF50",
        "directed": true,
        "end": 25,
        "id": 1152968783606841300,
        "label": "MANEUVERED_BETWEEN",
        "properties": {
         "label": "MANEUVERED_BETWEEN"
        },
        "start": 9,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#4CAF50",
        "directed": true,
        "end": 26,
        "id": 1155220583420526600,
        "label": "MANEUVERED_BETWEEN",
        "properties": {
         "label": "MANEUVERED_BETWEEN"
        },
        "start": 9,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#F44336",
        "directed": true,
        "end": 14,
        "id": 6917630182710837000,
        "label": "LAST_MONARCH_OF",
        "properties": {
         "label": "LAST_MONARCH_OF"
        },
        "start": 9,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#607D8B",
        "directed": true,
        "end": 18,
        "id": 6917632381734093000,
        "label": "SUCCEEDED",
        "properties": {
         "label": "SUCCEEDED"
        },
        "start": 9,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 11,
        "id": 1152931400211497000,
        "label": "SPOUSE",
        "properties": {
         "label": "SPOUSE"
        },
        "start": 10,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#CDDC39",
        "directed": true,
        "end": 11,
        "id": 1152957788490563600,
        "label": "SPOUSE_OF",
        "properties": {
         "label": "SPOUSE_OF"
        },
        "start": 10,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9E9E9E",
        "directed": true,
        "end": 9,
        "id": 1152958888002191400,
        "label": "RESTORED_TO_SUCCESSION",
        "properties": {
         "label": "RESTORED_TO_SUCCESSION"
        },
        "start": 10,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9C27B0",
        "directed": true,
        "end": 2,
        "id": 1153023759188230100,
        "label": "RELATED_TO",
        "properties": {
         "label": "RELATED_TO"
        },
        "start": 10,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#2196F3",
        "directed": true,
        "end": 17,
        "id": 1152961087025447000,
        "label": "BEQUEATHED_CROWN_TO",
        "properties": {
         "label": "BEQUEATHED_CROWN_TO"
        },
        "start": 16,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#4CAF50",
        "directed": true,
        "end": 17,
        "id": 1152962186537074700,
        "label": "DEPOSED_AND_EXECUTED",
        "properties": {
         "label": "DEPOSED_AND_EXECUTED"
        },
        "start": 18,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#F44336",
        "directed": true,
        "end": 20,
        "id": 1152964385560330200,
        "label": "HELD_TITLE",
        "properties": {
         "label": "HELD_TITLE"
        },
        "start": 19,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#607D8B",
        "directed": true,
        "end": 20,
        "id": 1153025958211485700,
        "label": "CREATED_AS",
        "properties": {
         "label": "CREATED_AS"
        },
        "start": 19,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#607D8B",
        "directed": true,
        "end": 23,
        "id": 1152956688978935800,
        "label": "CHILD_OF",
        "properties": {
         "label": "CHILD_OF"
        },
        "start": 22,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 72,
        "id": 6917529027641082000,
        "label": "BIRTH_DATE",
        "properties": {
         "label": "BIRTH_DATE"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#607D8B",
        "directed": true,
        "end": 10,
        "id": 1155208488792621000,
        "label": "CHILD_OF",
        "properties": {
         "label": "CHILD_OF"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#607D8B",
        "directed": true,
        "end": 73,
        "id": 6917564212013171000,
        "label": "CHILD_OF",
        "properties": {
         "label": "CHILD_OF"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#607D8B",
        "directed": true,
        "end": 74,
        "id": 6917564212013171000,
        "label": "CHILD_OF",
        "properties": {
         "label": "CHILD_OF"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#CDDC39",
        "directed": true,
        "end": 26,
        "id": 1152969883118469000,
        "label": "WAR",
        "properties": {
         "label": "WAR"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9E9E9E",
        "directed": true,
        "end": 1,
        "id": 1157474582257467400,
        "label": "MILITARY_CAMPAIGN",
        "properties": {
         "label": "MILITARY_CAMPAIGN"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9E9E9E",
        "directed": true,
        "end": 25,
        "id": 1155222782443782100,
        "label": "MILITARY_CAMPAIGN",
        "properties": {
         "label": "MILITARY_CAMPAIGN"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9E9E9E",
        "directed": true,
        "end": 29,
        "id": 1152970982630097000,
        "label": "MILITARY_CAMPAIGN",
        "properties": {
         "label": "MILITARY_CAMPAIGN"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9C27B0",
        "directed": true,
        "end": 30,
        "id": 1152972082141724700,
        "label": "REIGN",
        "properties": {
         "label": "REIGN"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#2196F3",
        "directed": true,
        "end": 36,
        "id": 1152976480188235800,
        "label": "NAMED_AFTER",
        "properties": {
         "label": "NAMED_AFTER"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#2196F3",
        "directed": true,
        "end": 37,
        "id": 1155228280001921000,
        "label": "NAMED_AFTER",
        "properties": {
         "label": "NAMED_AFTER"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#4CAF50",
        "directed": true,
        "end": 38,
        "id": 1152977579699863600,
        "label": "CHILD",
        "properties": {
         "label": "CHILD"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#F44336",
        "directed": true,
        "end": 39,
        "id": 1152978679211491300,
        "label": "BIRTHPLACE",
        "properties": {
         "label": "BIRTHPLACE"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#607D8B",
        "directed": true,
        "end": 39,
        "id": 6917599396385260000,
        "label": "BORN_IN",
        "properties": {
         "label": "BORN_IN"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#607D8B",
        "directed": true,
        "end": 70,
        "id": 6917599396385260000,
        "label": "BORN_IN",
        "properties": {
         "label": "BORN_IN"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 71,
        "id": 6917600495896887000,
        "label": "BORN_NEAR",
        "properties": {
         "label": "BORN_NEAR"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#CDDC39",
        "directed": true,
        "end": 82,
        "id": 6917609291989910000,
        "label": "GIVEN_TITLE",
        "properties": {
         "label": "GIVEN_TITLE"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9E9E9E",
        "directed": true,
        "end": 81,
        "id": 6917610391501537000,
        "label": "TITLE_DATE",
        "properties": {
         "label": "TITLE_DATE"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9C27B0",
        "directed": true,
        "end": 110,
        "id": 6917634580757348000,
        "label": "BORN_ON",
        "properties": {
         "label": "BORN_ON"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#2196F3",
        "directed": true,
        "end": 70,
        "id": 6917644476361998000,
        "label": "BORN_AT",
        "properties": {
         "label": "BORN_AT"
        },
        "start": 28,
        "styles": {},
        "thickness_factor": 1
       }
      ],
      "_graph_layout": {},
      "_highlight": [],
      "_license": {},
      "_model_module": "yfiles-jupyter-graphs",
      "_model_module_version": "^1.10.1",
      "_model_name": "GraphModel",
      "_neighborhood": {},
      "_nodes": [
       {
        "color": "#2196F3",
        "id": 4,
        "label": "Marie Curie",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Marie Curie",
         "label": "Person"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#4CAF50",
        "id": 8,
        "label": "Radioactivity",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Radioactivity",
         "label": "Researchfield"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#4CAF50"
       },
       {
        "color": "#F44336",
        "id": 6,
        "label": "University Of Paris",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "University Of Paris",
         "label": "Organization"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#F44336"
       },
       {
        "color": "#607D8B",
        "id": 7,
        "label": "Nobel Prize",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Nobel Prize",
         "label": "Award"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#607D8B"
       },
       {
        "color": "#4CAF50",
        "id": 12,
        "label": "Physics",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Physics",
         "label": "Researchfield"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#4CAF50"
       },
       {
        "color": "#4CAF50",
        "id": 13,
        "label": "Chemistry",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Chemistry",
         "label": "Researchfield"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#4CAF50"
       },
       {
        "color": "#2196F3",
        "id": 5,
        "label": "Pierre Curie",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Pierre Curie",
         "label": "Person"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#673AB7",
        "id": 9,
        "label": "Elizabeth I",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Elizabeth I",
         "label": "Person:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#CDDC39",
        "id": 1,
        "label": "Ireland",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Ireland",
         "label": "__Entity__:Place"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#CDDC39"
       },
       {
        "color": "#CDDC39",
        "id": 15,
        "label": "England",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "England",
         "label": "__Entity__:Place"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#CDDC39"
       },
       {
        "color": "#9E9E9E",
        "id": 14,
        "label": "House Of Tudor",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "House Of Tudor",
         "label": "__Entity__:Organization"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#9E9E9E"
       },
       {
        "color": "#673AB7",
        "id": 10,
        "label": "Henry Viii",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Henry Viii",
         "label": "Person:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#673AB7",
        "id": 11,
        "label": "Anne Boleyn",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Anne Boleyn",
         "label": "Person:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#673AB7",
        "id": 16,
        "label": "Edward Vi",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Edward Vi",
         "label": "Person:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#673AB7",
        "id": 18,
        "label": "Mary I",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Mary I",
         "label": "Person:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#673AB7",
        "id": 19,
        "label": "William Cecil",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "William Cecil",
         "label": "Person:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#9E9E9E",
        "id": 21,
        "label": "Church Of England",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Church Of England",
         "label": "__Entity__:Organization"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#9E9E9E"
       },
       {
        "color": "#673AB7",
        "id": 22,
        "label": "James Vi Of Scotland",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "James Vi Of Scotland",
         "label": "Person:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#673AB7",
        "id": 24,
        "label": "Sir Francis Walsingham",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Sir Francis Walsingham",
         "label": "Person:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#9C27B0",
        "id": 25,
        "label": "France",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "France",
         "label": "Country:__Entity__:Place"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#9C27B0"
       },
       {
        "color": "#CDDC39",
        "id": 26,
        "label": "Spain",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Spain",
         "label": "__Entity__:Place"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#CDDC39"
       },
       {
        "color": "#2196F3",
        "id": 2,
        "label": "Third Succession Act 1543",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Third Succession Act 1543",
         "label": "__Entity__:Event"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#673AB7",
        "id": 17,
        "label": "Lady Jane Grey",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Lady Jane Grey",
         "label": "Person:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#4CAF50",
        "id": 20,
        "label": "Baron Burghley",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Baron Burghley",
         "label": "__Entity__:Title"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#4CAF50"
       },
       {
        "color": "#673AB7",
        "id": 23,
        "label": "Mary, Queen Of Scots",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Mary, Queen Of Scots",
         "label": "Person:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#673AB7",
        "id": 28,
        "label": "Elizabeth",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Elizabeth",
         "label": "Person:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#F44336",
        "id": 72,
        "label": "18 December 1709 (O.S.)",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "18 December 1709 (O.S.)",
         "label": "__Entity__:Date"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#F44336"
       },
       {
        "color": "#673AB7",
        "id": 73,
        "label": "Peter The Great",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Peter The Great",
         "label": "Person:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#673AB7",
        "id": 74,
        "label": "Catherine",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Catherine",
         "label": "Person:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#CDDC39",
        "id": 29,
        "label": "Netherlands",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Netherlands",
         "label": "__Entity__:Place"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#CDDC39"
       },
       {
        "color": "#607D8B",
        "id": 30,
        "label": "Elizabethan Era",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Elizabethan Era",
         "label": "__Entity__:Time period"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#607D8B"
       },
       {
        "color": "#673AB7",
        "id": 36,
        "label": "Elizabeth Of York",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Elizabeth Of York",
         "label": "Person:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#673AB7",
        "id": 37,
        "label": "Lady Elizabeth Howard",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Lady Elizabeth Howard",
         "label": "Person:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#673AB7",
        "id": 38,
        "label": "Henry Viii Of England",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Henry Viii Of England",
         "label": "Person:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#CDDC39",
        "id": 39,
        "label": "Greenwich Palace",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Greenwich Palace",
         "label": "__Entity__:Place"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#CDDC39"
       },
       {
        "color": "#CDDC39",
        "id": 70,
        "label": "Kolomenskoye",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Kolomenskoye",
         "label": "__Entity__:Place"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#CDDC39"
       },
       {
        "color": "#673AB7",
        "id": 71,
        "label": "Moscow",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Moscow",
         "label": "__Entity__:Place:City"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#4CAF50",
        "id": 82,
        "label": "Tsarevna",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Tsarevna",
         "label": "__Entity__:Title"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#4CAF50"
       },
       {
        "color": "#F44336",
        "id": 81,
        "label": "6 March 1711",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "6 March 1711",
         "label": "__Entity__:Date"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#F44336"
       },
       {
        "color": "#F44336",
        "id": 110,
        "label": "7 September 1533",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "7 September 1533",
         "label": "__Entity__:Date"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#F44336"
       }
      ],
      "_overview": {
       "enabled": null,
       "overview_set": false
      },
      "_selected_graph": [
       [],
       []
      ],
      "_sidebar": {
       "enabled": false,
       "start_with": null
      },
      "_view_count": null,
      "_view_module": "yfiles-jupyter-graphs",
      "_view_module_version": "^1.10.1",
      "_view_name": "GraphView",
      "layout": "IPY_MODEL_c99b857b2235458fbe236ac4a199e8e9",
      "tabbable": null,
      "tooltip": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
